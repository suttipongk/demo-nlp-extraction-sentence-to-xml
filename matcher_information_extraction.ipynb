{"cells":[{"cell_type":"markdown","metadata":{"id":"wPYt-vRF303n"},"source":["# Setup\n","- pip uninstall spacy \n","- pip uninstall neuralcoref\n","- pip install spacy==2.1.0 \n","- pip install neuralcoref --no-binary neuralcoref\n","- python3 -m spacy download en\n","- USE MODEL : en_core_web_sm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KVW_wER52ePJ","vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install spacy==2.1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ru5bdNE4214H","vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install neuralcoref --no-binary neuralcoref"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Hbev6ZY8_7Q","vscode":{"languageId":"python"}},"outputs":[],"source":["!python3 -m spacy download en"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYvClOdR4U4V","vscode":{"languageId":"python"}},"outputs":[],"source":["from __future__ import print_function\n","import spacy\n","import neuralcoref\n","import os, sys\n","import re\n","import json\n","import array as arr\n","import uuid\n","from spacy import displacy\n","from spacy.matcher import Matcher\n","from json import JSONEncoder\n","import xml.etree.ElementTree as gfg\n","from xml.etree import ElementTree\n","import os.path\n","from nltk.tree import ParentedTree"]},{"cell_type":"markdown","metadata":{"id":"o1_2f6V57yJQ"},"source":["# Read File"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drMaVlIn5LKu","vscode":{"languageId":"python"}},"outputs":[],"source":["text = \"The Vacation Request Process starts when an employee of the organization submits a vacation request.\" \\\n","\"Once the requirement is registered, the request is received by the immediate supervisor; the supervisor must approve or reject the request.\" \\\n","\"If the request is rejected the application is returned to the applicant/employee who can review the rejection reasons.\" \\\n","\"If the request is approved a notification is generated to the Human Resources representative, who must complete the respective administrative procedures.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hdvwq7Z68igf","vscode":{"languageId":"python"}},"outputs":[],"source":["nlp = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"markdown","metadata":{"id":"lNqUcv5_7715"},"source":["# Resolve sentence from neuralcoref\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":930,"status":"ok","timestamp":1606635911841,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"1XxZgbED8DaY","outputId":"e1e489b7-c05e-4576-a7c2-d2bd0eb242ef","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["['The Vacation Request Process starts when an employee of the organization submits a vacation request.', 'Once the requirement is registered, a vacation request is received by the immediate supervisor; the immediate supervisor must approve or reject a vacation request.', 'If a vacation request is rejected the application is returned to the applicant/employee who can review the rejection reasons.', 'If a vacation request is approved a notification is generated to the Human Resources representative, who must complete the respective administrative procedures.']\n","AT INDEX 0 = The Vacation Request Process starts when an employee of the organization submits a vacation request.\n","AT INDEX 1 = Once the requirement is registered, a vacation request is received by the immediate supervisor; the immediate supervisor must approve or reject a vacation request.\n","AT INDEX 2 = If a vacation request is rejected the application is returned to the applicant/employee who can review the rejection reasons.\n","AT INDEX 3 = If a vacation request is approved a notification is generated to the Human Resources representative, who must complete the respective administrative procedures.\n"]}],"source":["import neuralcoref\n","\n","doc = nlp(text)\n","resolved_text = doc._.coref_resolved\n","sentences = [sent.string.strip() for sent in nlp(resolved_text).sents]\n","print(sentences)\n","\n","for index, text in enumerate(sentences):\n","  print (\"AT INDEX\", index, \"=\", text)\n","  #getNounPhrase(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1153,"status":"ok","timestamp":1606618679501,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"r12NIT-S6nSL","outputId":"785bb953-5819-44ec-c086-4e3e50b6563d","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["                       TOP                                                                                             \n","                        |                                                                                               \n","                        S                                                                                              \n","        ________________|___________________                                                                            \n","       |                                    VP                                                                         \n","       |                        ____________|____________________                                                       \n","       |                       |                                SBAR                                                   \n","       |                       |       __________________________|____________                                          \n","       |                       |      |                                       S                                        \n","       |                       |      |                       ________________|____________________                     \n","       |                       |      |                      NP                                    |                   \n","       |                       |      |          ____________|___                                  |                    \n","       |                       |      |         |                PP                                VP                  \n","       |                       |      |         |             ___|____                    _________|_____               \n","       NP                      |    WHADVP      NP           |        NP                 |               NP            \n","  _____|________________       |      |      ___|_____       |    ____|_______           |      _________|________      \n"," DT   NNP      NNP     NNP    VBZ    WRB    DT        NN     IN  DT           NN        VBZ    DT        NN       NN   \n"," |     |        |       |      |      |     |         |      |   |            |          |     |         |        |     \n","The Vacation Request Process starts  when   an     employee  of the      organization submits  a      vacation request.\n","\n"]}],"source":["import os, sys\n","from nltk import Tree\n","\n","#\"The Vacation Request Process starts when an employee of the organization submits a vacation request.\"\n","text = \"(TOP (S (NP (DT The) (NNP Vacation) (NNP Request) (NNP Process)) (VP (VBZ starts) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT an) (NN employee)) (PP (IN of) (NP (DT the) (NN organization)))) (VP (VBZ submits) (NP (DT a) (NN vacation) (NN request.))))))))\"\n","parsetree = Tree.fromstring(text)\n","parsetree.pretty_print()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":992,"status":"ok","timestamp":1606633175867,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"LmkKqGhO8B7F","outputId":"5d5d3d26-bb9f-4b95-b9d9-74ce7e1ce87f","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                                           TOP                                                                                      \n","                                                                            |                                                                                        \n","                                                                            S                                                                                       \n","       _____________________________________________________________________|_____________________________________________________________                           \n","     SBAR                                                                                                     |                           |                         \n","  ____|____________                                                                                           |                           |                          \n"," |                 S                                                                                          |                           |                         \n"," |          _______|_______________                                                                           |                           |                          \n"," |         |                       VP                                                                         |                           |                         \n"," |         |                _______|_________________                                                         |                           |                          \n"," |         |               |                         VP                                                       |                           |                         \n"," |         |               |        _________________|___________                                             |                           |                          \n"," |         |               |       |                            SBAR                                          |                           |                         \n"," |         |               |       |                             |                                            |                           |                          \n"," |         |               |       |                             S                                            |                           |                         \n"," |         |               |       |            _________________|______                                      |                           |                          \n"," |         |               |       |           |                        VP                                    |                           VP                        \n"," |         |               |       |           |            ____________|___                                  |               ____________|____                      \n"," |         |               |       |           |           |                VP                                |              |                 VP                   \n"," |         |               |       |           |           |      __________|___                              |              |       __________|_____                \n"," |         |               |       |           |           |     |              PP                            |              |      |     |          VP             \n"," |         |               |       |           |           |     |       _______|______                       |              |      |     |     _____|___            \n"," |         NP              |       |           NP          |     |      |              NP                     NP             |      VP    |    |         NP         \n"," |     ____|_______        |       |        ___|_____      |     |      |    __________|__________         ___|______        |      |     |    |      ___|_____      \n"," RB   DT           NN     VBZ     VBN      DT        NN   VBZ   VBN     IN  DT         JJ         NN      DT         NN      MD     VB    CC   VB    DT        NN   \n"," |    |            |       |       |       |         |     |     |      |   |          |          |       |          |       |      |     |    |     |         |     \n","Once the      requirement  is registered, the     request  is received  by the     immediate supervisor; the     supervisor must approve  or reject the     request.\n","\n"]}],"source":["import os, sys\n","from nltk import Tree\n","\n","#Once the requirement is registered, the request is received by the immediate supervisor; the supervisor must approve or reject the request.\n","text = \"(TOP (S (SBAR (RB Once) (S (NP (DT the) (NN requirement)) (VP (VBZ is) (VP (VBN registered,) (SBAR (S (NP (DT the) (NN request)) (VP (VBZ is) (VP (VBN received) (PP (IN by) (NP (DT the) (JJ immediate) (NN supervisor;))))))))))) (NP (DT the) (NN supervisor)) (VP (MD must) (VP (VP (VB approve)) (CC or) (VP (VB reject) (NP (DT the) (NN request.)))))))\"\n","nltk_tree = Tree.fromstring(text)\n","nltk_tree.pretty_print()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1002,"status":"ok","timestamp":1606619277495,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"KnvRsE1M93Hy","outputId":"bb797e55-e653-47c8-b947-90e521776d3a","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                           TOP                                                                               \n","                                                            |                                                                                 \n","                                                           SBAR                                                                              \n","  __________________________________________________________|___________________________________________________________________________      \n"," |             S                                                                                                                        |    \n"," |        _____|___________                                                                                                             |     \n"," |       |                 VP                                                                                                           |    \n"," |       |            _____|______                                                                                                      |     \n"," |       |           |            VP                                                                                                    |    \n"," |       |           |      ______|___________                                                                                          |     \n"," |       |           |     |                 SBAR                                                                                       |    \n"," |       |           |     |                  |                                                                                         |     \n"," |       |           |     |                  S                                                                                         |    \n"," |       |           |     |           _______|_____________                                                                            |     \n"," |       |           |     |          |                     VP                                                                          |    \n"," |       |           |     |          |                _____|__________                                                                 |     \n"," |       |           |     |          |               |                VP                                                               |    \n"," |       |           |     |          |               |      __________|________________________                                        |     \n"," |       |           |     |          |               |     |                                   PP                                      |    \n"," |       |           |     |          |               |     |       ____________________________|____                                   |     \n"," |       |           |     |          |               |     |      |                                 NP                                 |    \n"," |       |           |     |          |               |     |      |        _________________________|____                              |     \n"," |       |           |     |          |               |     |      |       |                             SBAR                           |    \n"," |       |           |     |          |               |     |      |       |                     _________|_____                        |     \n"," |       |           |     |          |               |     |      |       |                    |               S                       |    \n"," |       |           |     |          |               |     |      |       |                    |               |                       |     \n"," |       |           |     |          |               |     |      |       |                    |               VP                      |    \n"," |       |           |     |          |               |     |      |       |                    |     __________|___                    |     \n"," |       |           |     |          |               |     |      |       |                    |    |              VP                  |    \n"," |       |           |     |          |               |     |      |       |                    |    |     _________|___                |     \n"," |       NP          |     |          NP              |     |      |       NP                  WHNP  |    |             NP              |    \n"," |    ___|_____      |     |       ___|_______        |     |      |    ___|_________           |    |    |          ___|______         |     \n"," IN  DT        NN   VBZ   VBN     DT          NN     VBZ   VBN     TO  DT            NN         WP   MD   VB        DT         NN       .    \n"," |   |         |     |     |      |           |       |     |      |   |             |          |    |    |         |          |        |     \n"," If the     request  is rejected the     application  is returned  to the     applicant/employ who  can review     the     rejection reasons.\n","                                                                                     ee                                                      \n","\n"]}],"source":["import os, sys\n","from nltk import Tree\n","\n","#If the request is rejected the application is returned to the applicant/employee who can review the rejection reasons.\n","text = \"(TOP (SBAR (IN If) (S (NP (DT the) (NN request)) (VP (VBZ is) (VP (VBN rejected) (SBAR (S (NP (DT the) (NN application)) (VP (VBZ is) (VP (VBN returned) (PP (TO to) (NP (NP (DT the) (NN applicant/employee)) (SBAR (WHNP (WP who)) (S (VP (MD can) (VP (VB review) (NP (DT the) (NN rejection))))))))))))))) (. reasons.)))\"\n","parsetree = Tree.fromstring(text)\n","parsetree.pretty_print()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1192,"status":"ok","timestamp":1606619454751,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"l0dxsyux-elJ","outputId":"9e949d47-1199-43a4-bc3b-943bff7d12da","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["    TOP                                                                                                                                                                  \n","     |                                                                                                                                                                    \n","    SBAR                                                                                                                                                                 \n","  ___|__________                                                                                                                                                          \n"," |              S                                                                                                                                                        \n"," |         _____|___________                                                                                                                                              \n"," |        |                 VP                                                                                                                                           \n"," |        |            _____|______                                                                                                                                       \n"," |        |           |            VP                                                                                                                                    \n"," |        |           |      ______|___________                                                                                                                           \n"," |        |           |     |                 SBAR                                                                                                                       \n"," |        |           |     |                  |                                                                                                                          \n"," |        |           |     |                  S                                                                                                                         \n"," |        |           |     |           _______|_______________                                                                                                           \n"," |        |           |     |          |                       VP                                                                                                        \n"," |        |           |     |          |                 ______|______                                                                                                    \n"," |        |           |     |          |                |             VP                                                                                                 \n"," |        |           |     |          |                |       ______|________                                                                                           \n"," |        |           |     |          |                |      |               PP                                                                                        \n"," |        |           |     |          |                |      |       ________|____________________                                                                      \n"," |        |           |     |          |                |      |      |                             NP                                                                   \n"," |        |           |     |          |                |      |      |         ____________________|______________                                                       \n"," |        |           |     |          |                |      |      |        |                    |             SBAR                                                   \n"," |        |           |     |          |                |      |      |        |                    |          ____|______                                                \n"," |        |           |     |          |                |      |      |        |                    |         |           S                                              \n"," |        |           |     |          |                |      |      |        |                    |         |           |                                               \n"," |        |           |     |          |                |      |      |        |                    |         |           VP                                             \n"," |        |           |     |          |                |      |      |        |                    |         |     ______|______                                         \n"," |        |           |     |          |                |      |      |        |                    |         |    |             VP                                      \n"," |        |           |     |          |                |      |      |        |                    |         |    |       ______|______                                  \n"," |        NP          |     |          NP               |      |      |        NP                   |        WHNP  |      |             NP                               \n"," |    ____|_____      |     |       ___|_______         |      |      |    ____|_______             |         |    |      |       ______|__________________________       \n"," IN  DT         NN   VBZ   VBN     DT          NN      VBZ    VBN     TO  DT  NNP     NNPS          ,         WP   MD     VB     DT     JJ           JJ            NN    \n"," |   |          |     |     |      |           |        |      |      |   |    |       |            |         |    |      |      |      |            |             |      \n"," If the      request  is approved  a      notification  is generated  to the Human Resources representative, who  must complete the respective administrative procedures.\n","\n"]}],"source":["import os, sys\n","from nltk import Tree\n","\n","#If the request is approved a notification is generated to the Human Resources representative, who must complete the respective administrative procedures.\n","text = \"(TOP (SBAR (IN If) (S (NP (DT the) (NN request)) (VP (VBZ is) (VP (VBN approved) (SBAR (S (NP (DT a) (NN notification)) (VP (VBZ is) (VP (VBN generated) (PP (TO to) (NP (NP (DT the) (NNP Human) (NNPS Resources)) (, representative,) (SBAR (WHNP (WP who)) (S (VP (MD must) (VP (VB complete) (NP (DT the) (JJ respective) (JJ administrative) (NN procedures.)))))))))))))))))\"\n","parsetree = Tree.fromstring(text)\n","parsetree.pretty_print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dej7zvZFy1lv","vscode":{"languageId":"python"}},"outputs":[],"source":["def all_label(nltk_tree):\n","    for s in nltk_tree.subtrees():\n","        if s.label() != 'S' and s.label() != 'ROOT' and s.height() > 2:\n","            print(s.label() + ': ', end='')\n","            print(' '.join(s.leaves()).replace('_', ' '))\n","\n","def get_text_label(nltk_tree, get_label='NP'):\n","    for s in nltk_tree.subtrees():\n","        if s.label() == get_label:\n","            print(' '.join(s.leaves()).replace('_', ' '))\n","\n","def get_text_tag(nltk_tree, get_tag='N'):\n","    for s in nltk_tree.subtrees(lambda t: t.height() == 2):\n","        if s.label() == get_tag:\n","            print(s.leaves()[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":989,"status":"ok","timestamp":1606633184474,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"WCt0XP-tzC78","outputId":"09394e88-5df1-453d-82a8-401660c4429a","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["TOP: Once the requirement is registered, the request is received by the immediate supervisor; the supervisor must approve or reject the request.\n","SBAR: Once the requirement is registered, the request is received by the immediate supervisor;\n","NP: the requirement\n","VP: is registered, the request is received by the immediate supervisor;\n","VP: registered, the request is received by the immediate supervisor;\n","SBAR: the request is received by the immediate supervisor;\n","NP: the request\n","VP: is received by the immediate supervisor;\n","VP: received by the immediate supervisor;\n","PP: by the immediate supervisor;\n","NP: the immediate supervisor;\n","NP: the supervisor\n","VP: must approve or reject the request.\n","VP: approve or reject the request.\n","VP: approve\n","VP: reject the request.\n","NP: the request.\n"]}],"source":["all_label(nltk_tree)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":961,"status":"ok","timestamp":1606633206477,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"aSoyBY-czSbm","outputId":"1a76cb40-9e19-4a92-bb10-dc070109c3b7","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["the requirement\n","the request\n","the immediate supervisor;\n","the supervisor\n","the request.\n"]}],"source":["get_text_label(nltk_tree, 'NP')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCxYCVrhzWFi","vscode":{"languageId":"python"}},"outputs":[],"source":["get_text_tag(nltk_tree, 'N')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1104,"status":"ok","timestamp":1606633232557,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"Gzwq_mqazYxl","outputId":"2d8b2420-fd9b-46c8-8b50-eb3588a1113a","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["is registered, the request is received by the immediate supervisor;\n","registered, the request is received by the immediate supervisor;\n","is received by the immediate supervisor;\n","received by the immediate supervisor;\n","must approve or reject the request.\n","approve or reject the request.\n","approve\n","reject the request.\n"]}],"source":["get_text_label(nltk_tree, 'VP')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvzEKMpGzgL4","vscode":{"languageId":"python"}},"outputs":[],"source":["get_text_tag(nltk_tree, 'VBD')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1163,"status":"ok","timestamp":1606633313046,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"xXNxMgN9zi9j","outputId":"47d27618-79a7-485e-813d-1b32c5f9025e","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["by the immediate supervisor;\n"]}],"source":["get_text_label(nltk_tree, 'PP')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1075,"status":"ok","timestamp":1606633327208,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"KqaDbsYlzv20","outputId":"77e2bb85-7004-4821-8c0b-d4ca658b7773","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["by\n"]}],"source":["get_text_tag(nltk_tree, 'IN')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9P9SRdO4LVbd","vscode":{"languageId":"python"}},"outputs":[],"source":["#====================================================================================\n","#                                  SIGNAL WORD\n","#====================================================================================\n","SIGNAL_WORD = ['Once', 'Then', 'then', 'When', 'After', 'Afterwards', 'As soon as', 'Subsequently',\n","               'Upon', 'After that', 'Likewise', 'after which', 'Immediately after', 'In addition to',\n","               'In the following', 'Moreover', 'Thereafter', 'Therefore']\n","def check_signal_word_pattern(doc):\n","    for i in range(len(doc)-1):\n","        if doc[i].dep_ == 'mark' and doc[i].text in SIGNAL_WORD:\n","            return True\n","        return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9EwbqrH_RG2f","vscode":{"languageId":"python"}},"outputs":[],"source":["list_sentence = []\n","list_sentence_active = []\n","list_prep_word = []\n","\n","def condition_mark(token):\n","    if token.dep_ == \"mark\":\n","        if token.text in [\"If\"]:\n","            return True\n","    return False\n","\n","def find_dependency_active_sentence(token):\n","    if token.dep_ == \"nsubj\":\n","        word_left = \" \".join([token.text for token in token.lefts])\n","        list_sentence_active.append(word_left + \" \" + token.text + \"[nsubj]\")\n","    elif token.dep_ in [\"ROOT\"] and token.tag_ in [\"VBZ\"]:\n","        list_sentence_active.append(token.text + \"[verb]\")\n","    elif token.dep_ in [\"dobj\",\"ccomp\"]:\n","        word_left = \" \".join([token.text for token in token.lefts])\n","        list_sentence_active.append(word_left + \" \" + token.text + \"[dobj]\")\n","\n","def find_dependency_passive_sentence(token):\n","    if token.dep_ == \"nsubjpass\":\n","        list_sentence.append(token.text + \"[nsubjpass]\")\n","\n","    elif token.dep_ == \"ROOT\" and token.tag_ in [\"VBN\",\"VBD\"]:\n","        word_right = \" \".join([token.text for token in token.rights])\n","        list_sentence.append(token.text + \"[verb]\" + word_right)\n","\n","    elif token.dep_ == \"aux\":\n","        if token.text in [\"shall\",\"should\",\"will\",\"could\"]:\n","            list_sentence.append(token.text + \"[aux]\")\n","\n","    elif token.dep_ == \"prep\":\n","        word_right = \" \".join([token.text for token in token.rights])\n","        list_sentence.append(token.text + \"[prep]\" + word_right + \" \")\n","        list_prep_word.extend(word_right)\n","\n","    elif token.dep_ == \"pobj\":\n","        if list_prep_word is None:\n","            word_left = \" \".join([token.text for token in token.lefts])\n","            list_sentence.append(word_left + \" \" + token.text + \"[pobj]\")\n","\n","#====================================================================================\n","def active_sentence_match_pattern(text):\n","    nlp = spacy.load('en_core_web_sm')\n","    matcher = Matcher(nlp.vocab)\n","    doc = nlp(text)\n","    sents = list(doc.sents)\n","    print(\"Number of Sentences = \",len(sents))\n","    passive_rule = [{'DEP':'nsubj'},{'POS':'VERB'}]\n","    matcher.add('Passive',None,passive_rule)\n","    matches = matcher(doc)\n","    print(\"Match :\", len(matches))\n","\n","    for match in matches:\n","        match_id, start, end = match\n","        span = doc[start:end]\n","        print(match, span.text)\n","\n","def passive_sentence_match_pattern(text):\n","    nlp = spacy.load('en_core_web_sm')\n","    matcher = Matcher(nlp.vocab)\n","    doc = nlp(text)\n","    sents = list(doc.sents)\n","    print(\"Number of Sentences = \",len(sents))\n","    passive_rule = [{'DEP':'nsubjpass'},{'DEP':'aux','OP':'*'},{'DEP':'auxpass'},{'TAG':'VBN'}]\n","    matcher.add('Passive',None,passive_rule)\n","    matches = matcher(doc)\n","    print(\"Match :\", len(matches))\n","\n","    for match in matches:\n","        match_id, start, end = match\n","        span = doc[start:end]\n","        print(match, span.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":921,"status":"ok","timestamp":1606638657721,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"VgU7d9olFr-v","outputId":"7d7e0eb7-075c-4b2d-ae79-a896f11e24be","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Sentences =  1\n","Match : 2\n","(3889985946448656432, 2, 5) requirement is registered\n","(3889985946448656432, 7, 10) request is received\n"]}],"source":["text = \"Once the requirement is registered, the request is received by the immediate supervisor; the supervisor must approve or reject the request.\"\n","passive_sentence_match_pattern(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":921,"status":"ok","timestamp":1606638660007,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"BP8-geoPHoj6","outputId":"a56996e8-83ac-4fb1-a642-2a3e4f507e06","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Sentences =  1\n","Match : 1\n","(3889985946448656432, 16, 18) supervisor must\n"]}],"source":["text = \"Once the requirement is registered, the request is received by the immediate supervisor; the supervisor must approve or reject the request.\"\n","active_sentence_match_pattern(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b85vLXqm3fRN","vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install stanfordnlp"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAGw96dWgyvc","vscode":{"languageId":"python"}},"outputs":[],"source":["from nltk.tag.stanford import StanfordNERTagger\n","from nltk.tokenize import word_tokenize\n","import nltk\n","\n","!wget 'https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip'\n","!unzip stanford-ner-2018-10-16.zip\n","\n","nltk.download('punkt')\n","nltk.parse\n","\n","st = StanfordNERTagger('/content/stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz',\n","                       '/content/stanford-ner-2018-10-16/stanford-ner.jar',\n","                       encoding='utf-8')\n","\n","text = 'Once the requirement is registered, the request is received by the immediate supervisor; the supervisor must approve or reject the request.'\n","\n","tokenized_text = word_tokenize(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4337,"status":"ok","timestamp":1606638984584,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"NSY7mgFIhAyr","outputId":"cb8174bb-b003-4a62-8222-f5394fe01d43","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["[('Once', 'O'), ('the', 'O'), ('requirement', 'O'), ('is', 'O'), ('registered', 'O'), (',', 'O'), ('the', 'O'), ('request', 'O'), ('is', 'O'), ('received', 'O'), ('by', 'O'), ('the', 'O'), ('immediate', 'O'), ('supervisor', 'O'), (';', 'O'), ('the', 'O'), ('supervisor', 'O'), ('must', 'O'), ('approve', 'O'), ('or', 'O'), ('reject', 'O'), ('the', 'O'), ('request', 'O'), ('.', 'O')]\n"]}],"source":["classified_text = st.tag(tokenized_text)\n","print(classified_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdJFtNob0THq","vscode":{"languageId":"python"}},"outputs":[],"source":["import nltk\n","nltk.download('book')\n","nltk.download('tests')\n","nltk.download('all-corpora')# not recommended as it download huge amount of data.\n","nltk.download('punkt')\n","nltk.download('popular')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jp_nTb9ApuI","vscode":{"languageId":"python"}},"outputs":[],"source":["!unzip stanford-parser-3.5.1-models.jar"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3558,"status":"ok","timestamp":1606639012717,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"OVPH1X9Kk-G0","outputId":"5464112e-a8b9-4941-faa5-bf2a6437b677","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["'NoneType' object is not subscriptable\n","SUBJECT sub_tree.label() -> NP\n","each.label() -> NP\n","each.label() -> DT\n","each.label() -> NN\n","GET SUBJECT -> ['request']\n","PREDICATE sub_nodes.label() -> VP\n","'NoneType' object is not subscriptable\n","SUBJECT sub_tree.label() -> NP\n","each.label() -> NP\n","each.label() -> DT\n","each.label() -> NN\n","GET SUBJECT -> ['requirement']\n","PREDICATE sub_nodes.label() -> VP\n","SUBJECT sub_tree.label() -> NP\n","each.label() -> NP\n","each.label() -> DT\n","each.label() -> NN\n","GET SUBJECT -> ['supervisor']\n","PREDICATE sub_nodes.label() -> VP\n","[[{'subject': ['request'], 'predicate': ['received'], 'object': ['immediate']}]]\n"]}],"source":["import nltk\n","from nltk.tree import *\n","from nltk.parse import stanford\n","import nltk.data\n","import nltk.draw\n","\n","class SVO(object):\n","    \"\"\"\n","    Class Methods to Extract Subject Verb Object Tuples from a Sentence\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        Initialize the SVO Methods\n","        \"\"\"\n","        self.noun_types = [\"NN\", \"NNP\", \"NNPS\", \"NNS\", \"PRP\"]\n","        self.verb_types = [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]\n","        self.adjective_types = [\"JJ\", \"JJR\", \"JJS\"]\n","        self.pred_verb_phrase_siblings = None\n","        self.parser = stanford.StanfordParser(\n","            '/content/stanford-parser-3.5.1-models.jar',\n","            '/content/stanford-parser.jar'\n","        )\n","        self.sent_detector = nltk.data.load('nltk:tokenizers/punkt/english.pickle')\n","\n","    def get_attributes(self, node, parent_node, parent_node_siblings):\n","        \"\"\"\n","        returns the Attributes for a Node\n","        \"\"\"\n","\n","    def get_subject(self, sub_tree):\n","        \"\"\"\n","        Returns the Subject and all attributes for a subject, sub_tree is a Noun Phrase\n","\n","        :param sub_tree:\n","        :return:\n","        \"\"\"\n","        sub_nodes = sub_tree.subtrees()\n","        print(\"SUBJECT sub_tree.label() ->\", sub_tree.label())\n","        sub_nodes = [each for each in sub_nodes if each.pos()]\n","        subject = None\n","\n","        for each in sub_nodes:\n","            print(\"each.label() ->\", each.label())\n","            if each.label() in self.noun_types:\n","                subject = each.leaves()\n","                print(\"GET SUBJECT ->\", subject)\n","                break\n","\n","        return {'subject': subject}\n","\n","    def get_object(self, sub_tree):\n","        \"\"\"\n","        Returns an Object with all attributes of an object\n","        \"\"\"\n","        siblings = self.pred_verb_phrase_siblings\n","        Object = None\n","        for each_tree in sub_tree:\n","            if each_tree.label() in [\"NP\", \"PP\"]:\n","                sub_nodes = each_tree.subtrees()\n","                sub_nodes = [each for each in sub_nodes if each.pos()]\n","\n","                for each in sub_nodes:\n","                    if each.label() in self.noun_types:\n","                        Object = each.leaves()\n","                        break\n","                break\n","            else:\n","                sub_nodes = each_tree.subtrees()\n","                sub_nodes = [each for each in sub_nodes if each.pos()]\n","                for each in sub_nodes:\n","                    if each.label() in self.adjective_types:\n","                        Object = each.leaves()\n","                        break\n","                # Get first noun in the tree\n","        self.pred_verb_phrase_siblings = None\n","        return {'object': Object}\n","\n","    def get_predicate(self, sub_tree):\n","        \"\"\"\n","        Returns the Verb along with its attributes, Also returns a Verb Phrase\n","\n","        :param sub_tree:\n","        :return:\n","        \"\"\"\n","\n","        sub_nodes = sub_tree.subtrees()\n","        print(\"PREDICATE sub_nodes.label() ->\", sub_tree.label())\n","        sub_nodes = [each for each in sub_nodes if each.pos()]\n","        predicate = None\n","        sub_tree = ParentedTree.convert(sub_tree)\n","        for each in sub_nodes:\n","            if each.label() in self.verb_types:\n","                sub_tree = each\n","                predicate = each.leaves()\n","\n","        # get all predicate_verb_phrase_siblings to be able to get the object\n","        sub_tree = ParentedTree.convert(sub_tree)\n","        if predicate:\n","            pred_verb_phrase_siblings = self.tree_root.subtrees()\n","            pred_verb_phrase_siblings = [each for each in pred_verb_phrase_siblings if\n","                                         each.label() in [\"NP\", \"PP\", \"ADJP\", \"ADVP\"]]\n","            self.pred_verb_phrase_siblings = pred_verb_phrase_siblings\n","\n","        return {'predicate': predicate}\n","\n","    def process_parse_tree(self, parse_tree):\n","        \"\"\"\n","        Returns the Subject-Verb-Object Representation of a Parse Tree.\n","        Can Vary depending on number of 'sub-sentences' in a Parse Tree\n","        \"\"\"\n","        self.tree_root = parse_tree\n","        # Step 1 - Extract all the parse trees that start with 'S'\n","        output_list = []\n","        output_dict = {}\n","\n","        for idx, subtree in enumerate(parse_tree[0].subtrees()):\n","            subject = None\n","            predicate = None\n","            Object = None\n","            if subtree.label() in [\"S\", \"SQ\", \"SBAR\", \"SBARQ\", \"SINV\", \"FRAG\"]:\n","                children_list = subtree\n","                children_values = [each_child.label() for each_child in children_list]\n","                children_dict = dict(zip(children_values, children_list))\n","\n","                # Extract Subject, Verb-Phrase, Objects from Sentence sub-trees\n","                if children_dict.get(\"NP\") is not None:\n","                    subject = self.get_subject(children_dict[\"NP\"])\n","\n","                if children_dict.get(\"VP\") is not None:\n","                    # Extract Verb and Object\n","                    # i+=1\n","                    # \"\"\"\n","                    # if i==1:\n","                    #    pdb.set_trace()\n","                    # \"\"\"\n","                    predicate = self.get_predicate(children_dict[\"VP\"])\n","                    Object = self.get_object(children_dict[\"VP\"])\n","\n","                try:\n","                    if subject['subject'] and predicate['predicate'] and Object['object']:\n","                        output_dict['subject'] = subject['subject']\n","                        output_dict['predicate'] = predicate['predicate']\n","                        output_dict['object'] = Object['object']\n","                        output_list.append(output_dict)\n","                except Exception as e:\n","                    print(e)\n","                    continue\n","\n","        return output_list\n","\n","    def traverse(self, t):\n","        try:\n","            t.label()\n","        except AttributeError:\n","            print(t)\n","        else:\n","            # Now we know that t.node is defined\n","            print('(', t.label())\n","            for child in t:\n","                self.traverse(child)\n","\n","            print(')')\n","\n","    def sentence_split(self, text):\n","        \"\"\"\n","        returns the Parse Tree of a Sample\n","        \"\"\"\n","        sentences = self.sent_detector.tokenize(text)\n","        return sentences\n","\n","    def get_parse_tree(self, sentence):\n","        \"\"\"\n","        returns the Parse Tree of a Sample\n","        \"\"\"\n","        parse_tree = self.parser.raw_parse(sentence)\n","\n","        return parse_tree\n","\n","    def List_To_Tree(self, lst):\n","        if (not isinstance(lst, basestring)):\n","            if (len(lst) == 2 and isinstance(lst[0], str) and isinstance(lst[1], str)):\n","                lst = Tree(str(lst[0]).split('+')[0], [str(lst[1])])\n","            elif (isinstance(lst[0], str) and not isinstance(lst[1], str)):\n","                lst = Tree(str(lst[0]).split('+')[0], map(self.List_To_Tree, lst[1: len(lst)]))\n","        return lst\n","\n","svo = SVO()\n","sentence = \"Once the requirement is registered, the request is received by the immediate supervisor; the supervisor must approve or reject the request.\"\n","sentences = svo.sentence_split(sentence)\n","val = []\n","for sent in sentences:\n","    root_tree = svo.get_parse_tree(sent)\n","    val.append(svo.process_parse_tree(next(root_tree)))\n","print(val)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"elapsed":1635,"status":"ok","timestamp":1606727099479,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"IgrTN-gGbY1u","outputId":"a4cbfc6f-bf98-4b69-f4ca-d7d166c60678","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/html":["<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8e618ef7074b4f99b93a7ebec4795320-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Support</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Officer</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">updates</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">all</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">group</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n","</text>\n","\n","<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n","    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">calendars</tspan>\n","    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n","</text>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-8e618ef7074b4f99b93a7ebec4795320-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,89.5 395.0,89.5 395.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-8e618ef7074b4f99b93a7ebec4795320-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-8e618ef7074b4f99b93a7ebec4795320-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-8e618ef7074b4f99b93a7ebec4795320-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-8e618ef7074b4f99b93a7ebec4795320-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-8e618ef7074b4f99b93a7ebec4795320-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-8e618ef7074b4f99b93a7ebec4795320-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-8e618ef7074b4f99b93a7ebec4795320-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-8e618ef7074b4f99b93a7ebec4795320-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-8e618ef7074b4f99b93a7ebec4795320-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n","</g>\n","\n","<g class=\"displacy-arrow\">\n","    <path class=\"displacy-arc\" id=\"arrow-8e618ef7074b4f99b93a7ebec4795320-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n","    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n","        <textPath xlink:href=\"#arrow-8e618ef7074b4f99b93a7ebec4795320-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n","    </text>\n","    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n","</g>\n","</svg></span>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["text = \"The Support Officer updates all group calendars\"\n","\n","import spacy\n","from spacy import displacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(text)\n","displacy.render(doc, style='dep', jupyter=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qy0k4nhk7F1","vscode":{"languageId":"python"}},"outputs":[],"source":["import re \n","import string \n","import nltk \n","import spacy \n","import pandas as pd \n","import numpy as np \n","import math \n","from tqdm import tqdm \n","\n","from spacy.matcher import Matcher \n","from spacy.tokens import Span \n","from spacy import displacy \n","\n","pd.set_option('display.max_colwidth', 200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TBNrzRlUCFY0","vscode":{"languageId":"python"}},"outputs":[],"source":["#==================================================================================\n","#                                 GET NOUN PHRASE\n","#==================================================================================\n","def getNounPhrase(text):\n","    noun_chunks_list = []\n","    doc = nlp(text)\n","\n","    #Get Noun Phrase\n","    for np in doc.noun_chunks: \n","        noun_chunks_list.append(str(np))\n","    \n","    verbs = [tok for tok in doc if tok.pos_ == \"VERB\" and tok.dep_ != \"aux\"]\n","    for v in verbs:\n","        subs = getAllSubsLefts(v)\n","        dobj_right_word_list.append(getObjectRights(v))\n","    \n","    #==================================================================================\n","    #                       GET NOUN PHRASE RELATION WITH VERB\n","    #==================================================================================\n","    index = 0\n","    nounIndices = []\n","    for token in doc:\n","        if token.pos_ == 'NOUN':\n","            nounIndices.append(index)\n","        index = index + 1\n","\n","    for idxValue in nounIndices:\n","        doc = nlp(text)\n","        span = doc[doc[idxValue].left_edge.i : doc[idxValue].right_edge.i+1]\n","        span.merge()\n","\n","        for token in doc:\n","            if token.dep_ in SUBJECTS:\n","                nsubj_list.append(token.text)\n","            elif token.dep_ == 'dobj' or token.dep_ == 'pobj':\n","                dobj_list.append(token.text)\n","            elif token.dep_ == 'pobj' or token.pos_ == \"PRON\":\n","                pobj_list.append(token.text)\n","\n","    #==================================================================================\n","    #                            GET NSUBJ, DOBJ, POBJ \n","    #==================================================================================\n","\n","    #Get Noun Phrase\n","    print(\"nsubj_list :\", nsubj_list)\n","    print(\"dobj_list :\", dobj_list)\n","    print(\"pobj_list :\", pobj_list)\n","\n","    #==================================================================================\n","    #                             NSUBJ, DOBJ, POBJ \n","    #==================================================================================\n","    if not nsubj_list:\n","        print(\"  Activity  Compound\")\n","        all_subject = str(composite_activity_list[0]).replace('[','').replace(']','')\n","    else:\n","        all_subject = \" \".join(set(nsubj_list).intersection(noun_chunks_list))\n","        #  Subject \n","        if len(all_subject) == 0:\n","            all_subject = str(noun_chunks_list[0])\n","            print(\" =\", all_subject)\n","\n","    all_verb = str(verbs[0])\n","\n","    if not dobj_list:\n","        print(\" object\")\n","        all_object = str(dobj_right_word_list[0]).replace('[','').replace(']','')\n","    else:\n","        print(\" object  Noun Phrase\")\n","        all_object = \" \".join(set(dobj_list).intersection(noun_chunks_list))\n","    \n","    #==================================================================================\n","    #                             CREATE JSON OF SENTENCE\n","    #==================================================================================\n","    create_json_sentence(all_subject, all_verb, all_object)\n","\n","def getAllSubsLefts(v):\n","    subs = [tok for tok in v.lefts if tok.dep_ in SUBJECTS and tok.dep_ is not \"det\"]\n","    #  Activity  Compound\n","    getCompound(v)\n","    return subs\n","\n","def getCompound(v):\n","    compound = [tok for tok in v.lefts if tok.dep_ == \"compound\"]\n","    composite_activity_list.append(compound)\n","\n","def getObjectRights(v):\n","    object_sentence = [tok for tok in v.rights]\n","    return object_sentence\n","\n","def getMultipleVerbRights(v):\n","    multiple_verb_sentence = [tok for tok in v.rights if tok.dep_ == \"conj\"]\n","    return multiple_verb_sentence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6-f8DmZFWWM","vscode":{"languageId":"python"}},"outputs":[],"source":["#define the pattern \n","pattern = [{'POS':'NOUN'}, \n","           {'LOWER': 'such'}, \n","           {'LOWER': 'as'}, \n","           {'POS': 'PROPN'} #proper noun\n","          ]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1401,"status":"ok","timestamp":1606537346859,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"xC4oqDpKFm9b","outputId":"cf77689b-0181-4f42-8f18-bbf1fe57e781","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["countries such as Vietnam\n"]}],"source":["# Matcher class object \n","matcher = Matcher(nlp.vocab) \n","matcher.add(\"matching_1\", None, pattern) \n","\n","matches = matcher(doc) \n","span = doc[matches[0][1]:matches[0][2]] \n","\n","print(span.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":805,"status":"ok","timestamp":1606537454706,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"0hAfx1exGBWR","outputId":"72e15bac-9b3b-4c9b-f21f-2f24eecf9ad1","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["developing countries such as Vietnam\n"]}],"source":["# Matcher class object\n","matcher = Matcher(nlp.vocab)\n","\n","#define the pattern\n","pattern = [{'DEP':'amod', 'OP':\"?\"}, # adjectival modifier\n","           {'POS':'NOUN'},\n","           {'LOWER': 'such'},\n","           {'LOWER': 'as'},\n","           {'POS': 'PROPN'}]\n","\n","matcher.add(\"matching_1\", None, pattern)\n","matches = matcher(doc)\n","\n","span = doc[matches[0][1]:matches[0][2]]\n","print(span.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1051,"status":"ok","timestamp":1606537633268,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"8gpiIEFEGs8P","outputId":"d8a53776-73e3-4964-e3dd-65c087bc13da","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["car and other vehicles\n"]}],"source":["# Matcher class object \n","matcher = Matcher(nlp.vocab) \n","\n","#define the pattern \n","pattern = [{'DEP':'amod', 'OP':\"?\"}, \n","           {'POS':'NOUN'}, \n","           {'LOWER': 'and', 'OP':\"?\"}, \n","           {'LOWER': 'or', 'OP':\"?\"}, \n","           {'LOWER': 'other'}, \n","           {'POS': 'NOUN'}] \n","           \n","matcher.add(\"matching_1\", None, pattern) \n","\n","matches = matcher(doc) \n","span = doc[matches[0][1]:matches[0][2]] \n","print(span.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1014,"status":"ok","timestamp":1606537723694,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"s1x46AM9HDAN","outputId":"de5652f8-d6c5-4b23-b665-f51fda2c98c8","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Eight people, including two children\n"]}],"source":["# Matcher class object \n","matcher = Matcher(nlp.vocab) \n","\n","#define the pattern \n","pattern = [{'DEP':'nummod','OP':\"?\"}, # numeric modifier \n","           {'DEP':'amod','OP':\"?\"}, # adjectival modifier \n","           {'POS':'NOUN'}, \n","           {'IS_PUNCT': True}, \n","           {'LOWER': 'including'}, \n","           {'DEP':'nummod','OP':\"?\"}, \n","           {'DEP':'amod','OP':\"?\"}, \n","           {'POS':'NOUN'}] \n","                               \n","matcher.add(\"matching_1\", None, pattern) \n","\n","matches = matcher(doc) \n","span = doc[matches[0][1]:matches[0][2]] \n","print(span.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1166,"status":"ok","timestamp":1606537852723,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"Vwhpt0L0HidZ","outputId":"e68b5170-9197-490d-e444-ea1b753a90bb","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["fruits, especially whole fruits\n"]}],"source":["# Matcher class object \n","matcher = Matcher(nlp.vocab)\n","\n","#define the pattern \n","pattern = [{'DEP':'nummod','OP':\"?\"}, \n","           {'DEP':'amod','OP':\"?\"}, \n","           {'POS':'NOUN'}, \n","           {'IS_PUNCT':True}, \n","           {'LOWER': 'especially'}, \n","           {'DEP':'nummod','OP':\"?\"}, \n","           {'DEP':'amod','OP':\"?\"}, \n","           {'POS':'NOUN'}] \n","           \n","matcher.add(\"matching_1\", None, pattern) \n","\n","matches = matcher(doc) \n","span = doc[matches[0][1]:matches[0][2]] \n","print(span.text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8_kjmopH3CD","vscode":{"languageId":"python"}},"outputs":[],"source":["def subtree_matcher(doc): \n","  x = '' \n","  y = '' \n","  \n","  # iterate through all the tokens in the input sentence \n","  for i,tok in enumerate(doc): \n","    # extract subject \n","    if tok.dep_.find(\"subjpass\") == True: \n","      y = tok.text \n","      \n","    # extract object \n","    if tok.dep_.endswith(\"obj\") == True: \n","      x = tok.text \n","      \n","  return x,y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":862,"status":"ok","timestamp":1606537953035,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"1w5i7MmgH7IE","outputId":"a10971c1-0181-493b-dfc9-cab493b8f99c","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["('Uber', 'Careem')"]},"execution_count":19,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["text_2 = \"Careem, a ride hailing major in middle east, was acquired by Uber.\" \n","\n","doc_2 = nlp(text_2) \n","subtree_matcher(doc_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":911,"status":"ok","timestamp":1606537976521,"user":{"displayName":"Sut","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiqTtYUEpWQsymNl0gpoWkeQVgPIM3Wq21YCM51xtw=s64","userId":"11673919771648604082"},"user_tz":-420},"id":"9zjqP0UPIA46","outputId":"5cff706b-c2d6-4335-b887-b2f041446344","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["('Tableau', '')"]},"execution_count":20,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["text_3 = \"Salesforce recently acquired Tableau.\" \n","doc_3 = nlp(text_3) \n","subtree_matcher(doc_3)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Matcher Information Extraction.ipynb","provenance":[{"file_id":"1v2Pr5HC8JFpm7EarC0EVDnxiRliQ7haj","timestamp":1575114088415}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
